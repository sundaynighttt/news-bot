import gspread
from google.oauth2.service_account import Credentials
from datetime import datetime, timedelta
from collections import defaultdict
import os
import base64
import requests
from logging_config import setup_logger, log_execution_time
from error_handler import error_handler

# ë¡œê±° ì„¤ì •
logger = setup_logger('weekly_summary')
start_time = datetime.now()

# ë³µí˜¸í™”ëœ credentials ìƒì„±
b64_cred = os.environ['GOOGLE_CREDENTIALS']
os.makedirs("google_upload", exist_ok=True)
with open("google_upload/credentials.json", "w") as f:
    f.write(base64.b64decode(b64_cred).decode('utf-8'))

SERVICE_ACCOUNT_FILE = 'google_upload/credentials.json'
SPREADSHEET_ID = '1KBDB7D5sTvCGM-thDkYCnO-2kvsSoQc4RxDGoOO4Rdk'
SOURCE_SHEET = 'ë‰´ìŠ¤ìš”ì•½'
TARGET_SHEET = 'ì£¼ê°„ìš”ì•½'

def fetch_week_news():
    scopes = ['https://www.googleapis.com/auth/spreadsheets']
    credentials = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=scopes)
    gc = gspread.authorize(credentials)
    sh = gc.open_by_key(SPREADSHEET_ID)
    ws = sh.worksheet(SOURCE_SHEET)
    rows = ws.get_all_values()[1:]

    today = datetime.now() + timedelta(hours=9)
    week_dates = [(today - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(7)]
    filtered = [r for r in rows if r[0] in week_dates and "ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨" not in r[3]]
    return filtered, sh

def get_weekly_summary(texts):
    prompt = f"""ì•„ë˜ëŠ” ì´ë²ˆ ì£¼ì˜ ì£¼ìš” ê²½ì œ ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì„ ìš”ì•½í•˜ì—¬ ì•„íŒŒíŠ¸ íˆ¬ìì ì…ì¥ì—ì„œ ì˜ë¯¸ ìˆëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”.
    
{texts}

ìš”ì•½:"""

    headers = {
        "x-api-key": os.environ['ANTHROPIC_API_KEY'],
        "anthropic-version": "2023-06-01",
        "Content-Type": "application/json",
    }
    data = {
        "model": "claude-3-haiku-20240307",
        "max_tokens": 500,
        "temperature": 0.5,
        "messages": [{"role": "user", "content": prompt}]
    }

    try:
        response = requests.post("https://api.anthropic.com/v1/messages", headers=headers, json=data)
        return response.json()["content"][0]["text"].strip()
    except:
        return "ìš”ì•½ ì‹¤íŒ¨"

@error_handler('weekly_summary')
def main():
    logger.info("ì£¼ê°„ ìš”ì•½ ìƒì„± ì‹œì‘")
    rows, sh = fetch_week_news()
    if not rows:
        logger.warning("ì´ë²ˆ ì£¼ ë°ì´í„° ì—†ìŒ")
        print("ì´ë²ˆ ì£¼ ë°ì´í„° ì—†ìŒ")
        return

    grouped = defaultdict(list)
    for row in rows:
        cat, title, summary, link = row[1], row[2], row[3], row[4]
        grouped[cat].append(f"{title}\n{summary}\n{link}")

    today = (datetime.now() + timedelta(hours=9)).strftime('%Y-%m-%d')
    weekly_output = [f"ğŸ“… {today} ì£¼ê°„ ê²½ì œ ë‰´ìŠ¤ ìš”ì•½\n"]
    
    logger.info("ì¹´í…Œê³ ë¦¬ë³„ ì¸ì‚¬ì´íŠ¸ ìƒì„±")
    for cat, texts in grouped.items():
        joined = "\n\n".join(texts[:5])
        insight = get_weekly_summary(joined)
        weekly_output.append(f"ğŸ“Œ {cat} ì¸ì‚¬ì´íŠ¸\n{insight}\n")

    output_text = "\n\n".join(weekly_output)

    logger.info("Google Sheetsì— ì €ì¥")
    try:
        ws = sh.worksheet(TARGET_SHEET)
    except:
        ws = sh.add_worksheet(title=TARGET_SHEET, rows="100", cols="2")
        ws.append_row(["ë‚ ì§œ", "ìš”ì•½"])
    
    ws.append_row([today, output_text], value_input_option='RAW')
    logger.info("ì£¼ê°„ ìš”ì•½ ì €ì¥ ì™„ë£Œ")
    log_execution_time(logger, start_time, 'weekly_summary')
    
    print(output_text)

if __name__ == "__main__":
    main()
