import os
import sys
import requests
from bs4 import BeautifulSoup

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€ (GitHub Actions í˜¸í™˜ì„± ìœ ì§€)
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from src.utils import get_kst_date, get_year_month_path
from src.config import KEYWORDS, NEWS_URL, RAW_DATA_DIR


def extract_first_paragraph(url):
    """ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì²« ë²ˆì§¸ ë¬¸ë‹¨ ì¶”ì¶œ"""
    try:
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        soup = BeautifulSoup(res.text, 'html.parser')
        content = soup.select_one("#dic_area")
        if content:
            paragraphs = content.get_text(strip=True).split('\n')
            for p in paragraphs:
                if len(p.strip()) > 30:
                    return p.strip()
        return "ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨"
    except:
        return "ë³¸ë¬¸ ìš”ì²­ ì‹¤íŒ¨"


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    res = requests.get(NEWS_URL)
    soup = BeautifulSoup(res.text, 'html.parser')
    articles = soup.select('.rankingnews_box a')

    results = {k: [] for k in KEYWORDS}
    for article in articles:
        title = article.text.strip()
        href = article['href']
        if not href.startswith("http"):
            link = "https://news.naver.com" + href
        else:
            link = href

        for category, words in KEYWORDS.items():
            if any(word in title for word in words):
                if len(results[category]) < 10:
                    paragraph = extract_first_paragraph(link)
                    results[category].append((title, link, paragraph))
                break

    # ë‚ ì§œë³„ í´ë” ìƒì„±
    today = get_kst_date()
    year_month = get_year_month_path()
    output_dir = os.path.join(RAW_DATA_DIR, year_month)
    os.makedirs(output_dir, exist_ok=True)
    
    # ì €ì¥ ê²½ë¡œ
    output_file = os.path.join(output_dir, f"output_{today}.md")
    
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(f"# ğŸ“… {today} ë„¤ì´ë²„ ê²½ì œ í‚¤ì›Œë“œ ë‰´ìŠ¤ ìš”ì•½\n\n")
        for cat, items in results.items():
            if len(items) >= 3:
                f.write(f"## ğŸ“Œ {cat}\n\n")
                for i, (title, link, para) in enumerate(items[:10], 1):
                    f.write(f"{i}. **{title}**\n   - {para}\n   - [ê¸°ì‚¬ ë§í¬]({link})\n\n")
    
    print(f"ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ: {output_file}")


if __name__ == "__main__":
    main()
